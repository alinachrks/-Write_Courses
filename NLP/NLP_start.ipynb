{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59a2297f",
   "metadata": {},
   "source": [
    "# Автоматическая обработка текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78637fd",
   "metadata": {},
   "source": [
    "[Список полезных библиотек для обработки текста](https://nlpub.ru/%D0%9E%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B0_%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%B0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1249b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "28c6b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Возьмём предлодение:\n",
    "\n",
    "sentence = ['Образование само по себе имеет ценность, независимо от того, \\\n",
    "            какое экономическое воздействие оно оказывает на общество.']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0d0e1d",
   "metadata": {},
   "source": [
    "Для того, чтобы данное предложение было машиночитаемым, переведём его в математический объект"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "11556bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\kasutaja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kasutaja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\kasutaja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (1.24.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\kasutaja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\kasutaja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (1.9.3)\n"
     ]
    }
   ],
   "source": [
    "# Установим библиотеку scikit-learn\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534f78b3",
   "metadata": {},
   "source": [
    "Используя модуль CountVectorizer библиотеки scikit-learn, можно векторизовать предыдущее предложение и сгенерировать выходную матрицу с вектором:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "11a2d85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit_transform(sentence).todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32958a84",
   "metadata": {},
   "source": [
    "Библиотека Natural Language Toolkit ( NLTK ) — одна из самых популярных библиотек Python для обработки естественного языка. Она была разработана Стивеном Бердом и Эдвардом Лопером из Пенсильванского университета. Эта библиотека, разработанная учеными и исследователями, предназначена для поддержки исследований в области NLP и содержит набор обучающих ресурсов, которые предоставляют отличный способ изучения NLP.\n",
    "\n",
    "Официальный сайт NLTK: https://www.nltk.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "508c281b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\kasutaja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\kasutaja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: click in c:\\users\\kasutaja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kasutaja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\kasutaja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\kasutaja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "# установим NLTK:\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab3415b",
   "metadata": {},
   "source": [
    "#### Корпуса НЛТК\n",
    "Корпус — это большой массив текстовых или лингвистических данных, который очень важен в NLP-исследованиях для разработки и тестирования приложений. NLTK позволяет пользователям получить доступ к более чем 50 корпусам и лексическим ресурсам (многие из них сопоставлены с приложениями на основе ML). Мы можем импортировать любой из доступных корпусов в нашу программу и использовать функции NLTK для анализа текста в импортированном корпусе.  \n",
    "Более подробную информацию о каждом корпусе можно найти здесь: http://www.nltk.org/book/ch02.html."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef0747e",
   "metadata": {},
   "source": [
    "#### Обработка текста\n",
    "Ключевой частью NLP является преобразование текста в математические объекты. NLTK предоставляет различные функции, которые помогают нам преобразовывать текст в векторы. Самая основная функция NLTK для этой цели — токенизация, которая разбивает документ на список единиц. Этими единицами могут быть слова, алфавиты или предложения.\n",
    "\n",
    "Обратитесь к следующему фрагменту кода, чтобы выполнить токенизацию с помощью библиотеки NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "bbc4fc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Для', 'писателя', 'самое', 'ценное', '—', 'читать', 'всё', ',', 'что', 'попадется', 'ему', 'в', 'руки', ',', 'следовать', 'его', 'порыву', '.']\n"
     ]
    }
   ],
   "source": [
    "# загрузим NKTL:\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = 'Для писателя самое ценное — читать всё, что попадется ему в руки, следовать его порыву.'\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f483494d",
   "metadata": {},
   "source": [
    "Мы токенизировали предыдущее предложение, используя word_tokenize() - функцию NLTK, которая просто разбивает предложение пробелами. На выходе получается список, который является первым шагом к векторизации.\n",
    "\n",
    "Для рационализации векторов обычно используют некоторые другие полезные функции NLTK, такие как стоп-слова, лемматизация и выделение корней\n",
    "\n",
    "Выполнив код ниже, вы получите список русских стоп-слов в NLTK. Стоп-слова — это в основном слова-связки, которые не сильно влияют на смысл предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "64862013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Kasutaja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('russian')\n",
    "\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "cf76a67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# подсчитаем количество стоп-слов в этом списке, запросив длину списка:\n",
    "\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39af55a5",
   "metadata": {},
   "source": [
    "Этот список далеко не отвечает действительному набору большей части стоп-слов в русском языке, поэтому рекомендуется дополнять его для каждой задачи отдельно, либо использовать другие списки стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "09ff0a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['которых', 'которые', 'твой', 'которой', 'которого', 'сих', 'ком', 'свой', 'твоя', 'этими', 'слишком', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'нами', 'всему', 'будь', 'саму', 'чаще', 'ваше', 'сами', 'наш', 'затем', 'еще', 'самих', 'наши', 'ту', 'каждое', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'мочь', 'весь', 'этим', 'наша', 'своих', 'оба', 'который', 'зато', 'те', 'этих', 'вся', 'ваш', 'такая', 'теми', 'ею', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'которая', 'нередко', 'каждая', 'также', 'чему', 'собой', 'самими', 'нем', 'вами', 'ими', 'откуда', 'такие', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'тому', 'та', 'очень', 'сама', 'нему', 'алло', 'оно', 'этому', 'кому', 'тобой', 'таки', 'твоё', 'каждые', 'твои', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'мой', 'нею', 'самим', 'ваши', 'ваша', 'кем', 'мои', 'однако', 'сразу', 'свое', 'ними', 'всё', 'неё', 'тех', 'хотя', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'всем', 'тобою', 'тебе', 'одной', 'другие', 'этао', 'само', 'эта', 'буду', 'самой', 'моё', 'своей', 'такое', 'всею', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'будут', 'своего', 'кого', 'свои', 'мог', 'нам', 'особенно', 'её', 'самому', 'наше', 'кроме', 'вообще', 'вон', 'мною', 'никто', 'это']\n"
     ]
    }
   ],
   "source": [
    "# строка из новых стоп-слов\n",
    "stop_words_1 = 'которых которые твой которой которого сих ком свой твоя этими слишком \\\n",
    "                  нами всему будь саму чаще ваше сами наш затем еще самих наши ту каждое \\\n",
    "                  мочь весь этим наша своих оба который зато те этих вся ваш такая теми ею \\\n",
    "                  которая нередко каждая также чему собой самими нем вами ими откуда такие \\\n",
    "                  тому та очень сама нему алло оно этому кому тобой таки твоё каждые твои \\\n",
    "                  мой нею самим ваши ваша кем мои однако сразу свое ними всё неё тех хотя \\\n",
    "                  всем тобою тебе одной другие этао само эта буду самой моё своей такое всею \\\n",
    "                  будут своего кого свои мог нам особенно её самому наше кроме вообще вон мною никто это'\n",
    "\n",
    "# преобразование строки в список\n",
    "stop_words_1 = stop_words_1.split(' ')\n",
    "\n",
    "print(stop_words_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "21f7aab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'алло', 'буду', 'будут', 'будь', 'вами', 'ваш', 'ваша', 'ваше', 'ваши', 'весь', 'вон', 'вообще', 'всем', 'всему', 'всею', 'вся', 'всё', 'другие', 'еще', 'ею', 'её', 'затем', 'зато', 'ими', 'каждая', 'каждое', 'каждые', 'кем', 'кого', 'ком', 'кому', 'которая', 'которого', 'которой', 'которые', 'который', 'которых', 'кроме', 'мною', 'мог', 'мои', 'мой', 'мочь', 'моё', 'нам', 'нами', 'наш', 'наша', 'наше', 'наши', 'нем', 'нему', 'нередко', 'нею', 'неё', 'никто', 'ними', 'оба', 'однако', 'одной', 'оно', 'особенно', 'откуда', 'очень', 'сама', 'сами', 'самим', 'самими', 'самих', 'само', 'самой', 'самому', 'саму', 'свое', 'своего', 'своей', 'свои', 'своих', 'свой', 'сих', 'слишком', 'собой', 'сразу', 'та', 'такая', 'также', 'таки', 'такие', 'такое', 'твои', 'твой', 'твоя', 'твоё', 'те', 'тебе', 'теми', 'тех', 'тобой', 'тобою', 'тому', 'ту', 'хотя', 'чаще', 'чему', 'эта', 'этао', 'этим', 'этими', 'этих', 'это', 'этому']\n"
     ]
    }
   ],
   "source": [
    "stop_words_1.sort()\n",
    "print(stop_words_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "9007b2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_1 = ['алло', 'буду', 'будут', 'будь', 'вами', 'ваш', 'ваша', 'ваше', 'ваши', 'весь',\n",
    "    'вон', 'вообще', 'всем', 'всему', 'всею', 'вся', 'всё', 'другие', 'еще', 'ею',\n",
    "    'её', 'затем', 'зато', 'ими', 'каждая', 'каждое', 'каждые', 'кем', 'кого', 'ком',\n",
    "    'кому', 'которая', 'которого', 'которой', 'которые', 'который', 'которых', 'кроме',\n",
    "    'мною', 'мог', 'мои', 'мой', 'мочь', 'моё', 'нам', 'нами', 'наш', 'наша', 'наше',\n",
    "    'наши', 'нем', 'нему', 'нередко', 'нею', 'неё', 'никто', 'ними', 'оба', 'однако', \n",
    "    'одной', 'оно', 'особенно', 'откуда', 'очень', 'сама', 'сами', 'самим', 'самими', \n",
    "    'самих', 'само', 'самой', 'самому', 'саму', 'свое', 'своего', 'своей', 'свои', \n",
    "    'своих', 'свой', 'сих', 'слишком', 'собой', 'сразу', 'та', 'такая', 'также', 'таки', \n",
    "    'такие', 'такое', 'твои', 'твой', 'твоя', 'твоё', 'те', 'тебе', 'теми', 'тех', \n",
    "    'тобой', 'тобою', 'тому', 'ту', 'хотя', 'чаще', 'чему', 'эта', 'этао', 'этим', \n",
    "    'этими', 'этих', 'это', 'этому']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "1b48916d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['а', 'а. л.', 'а.л.', 'а/о', 'аа', 'а-а', 'ааа', 'а-а-а', 'а-а-а-а', 'абы', 'авось', 'авт. л.', 'авт.л.', 'ага', 'адм.-терр.', 'аж', 'аз', 'ай', 'ай-ай-ай', 'айда', 'ай-яй-яй', 'акад.', 'аки', 'але', 'али', 'алле', 'алло', 'аль', 'а-ля', 'аминь', 'ан', 'апчхи', 'атас', 'ау', 'аф', 'ах', 'ахти', 'аще', 'б', 'б', 'ба', 'бабах', 'ба-бах', 'баста', 'бах', 'бац', 'без', 'безо', 'бен', 'бис', 'бишь', 'б-ка', 'благо', 'благодаря', 'близ', 'бо', 'более', 'больше', 'бом', 'браво', 'брр', 'бррр', 'брысь', 'бу-бу-бу', 'буде', 'будто', 'буль-буль', 'бум', 'бы', 'было', 'в', 'в.', 'в/о', 'вай', 'ван', 'вау', 'ваш', 'вблизи', 'вв.', 'ввиду', 'вглубь', 'вдоль', 'вдруг', 'ведь', 'везде', 'весь', 'весьма', 'взамен', 'виват', 'вишь', 'вкз.', 'включая', 'вкруг', 'вместе', 'вместо', 'вне', 'внизу', 'внутри', 'внутрь', 'во', 'во-во', 'возле', 'возможно', 'вокруг', 'вон', 'вона', 'вообще', 'вообще-то', 'во-он', 'во-от', 'вопреки', 'вослед', 'вост.-европ.', 'вот', 'вперед', 'впереди', 'вполне', 'впрочем', 'впрямь', 'вроде', 'все', 'всегда', 'всего', 'все-таки', 'вслед', 'вследствие', 'всюду', 'всякий', 'всяко', 'всякое', 'вы', 'выше', 'г', 'г.', 'гг.', 'гг.', 'г-да', 'где', 'где-либо', 'где-нибудь', 'где-то', 'геть', 'г-жа', 'глядь', 'гм', 'г-н', 'гоп', 'гор.', 'гос.', 'гос-во', 'господи', 'гр.', 'гр-ка', 'гр-не', 'гы', 'д. о.', 'д.о.', 'д/о', 'да', 'да', 'да-а', 'да-а-а', 'дабы', 'давай', 'давайте', 'давно', 'да-да', 'да-да-да', 'даже', 'дай', 'дайте', 'дак', 'далее', 'данный', 'д-да', 'де', 'действительно', 'дель', 'ден', 'деп.', 'дер', 'дер.', 'ди', 'дисс.', 'для', 'до', 'добро', 'довольно', 'доколе', 'дол.', 'долл.', 'дон', 'доселе', 'дотоле', 'другие', 'другое', 'другой', 'дудки', 'ды', 'дык', 'его', 'едва', 'ее', 'ежедн.', 'ежели', 'ежли', 'ей-богу', 'ей-ей', 'ейный', 'елки-палки', 'е-мое', 'если', 'ет', 'ето', 'етот', 'еще', 'ж', 'ж.', 'ж. д.', 'ж.д.', 'ж.-д.', 'ж/д', 'же', 'жен.', 'з.', 'з. к.', 'з.к.', 'з/к', 'з/о', 'за', 'заместо', 'зап.', 'зап.-европ.', 'заруб.', 'затем', 'зато', 'зачем', 'зачем-то', 'здесь', 'здеся', 'здорово', 'здравствуй', 'здравствуйте', 'здрасте', 'значит', 'зы', 'и', 'и т. д.', 'и т. д. и т. п.', 'и т. п.', 'и т.д.', 'и т.д. и т.п.', 'и т.п.', 'и. о.', 'и.о.', 'ибн', 'ибо', 'иже', 'из', 'изд-во', 'из-за', 'изнутри', 'изо', 'из-под', 'и-и', 'или', 'иль', 'именно', 'имхо', 'ин', 'ин.', 'иначе', 'иной', 'иностр.', 'инст.', 'ин-т', 'исключая', 'исключительно', 'итак', 'ить', 'их', 'ихний', 'ишь', 'к', 'к.', 'ка', 'ка-ак', 'кабы', 'каждый', 'кажный', 'как', 'как-либо', 'как-нибудь', 'как-никак', 'како', 'каков', 'каково', 'каковой', 'какой', 'какой-либо', 'какой-нибудь', 'какой-никакой', 'какой-то', 'как-то', 'канд.', 'караул', 'касательно', 'кв.', 'кг', 'кг.', 'кис-кис', 'ко', 'когда', 'когда-либо', 'когда-нибудь', 'когда-то', 'кое', 'кое-где', 'кое-как', 'кое-какой', 'кое-кто', 'кое-что', 'кой', 'кой-какой', 'кой-кто', 'кой-то', 'кой-что', 'коли', 'коль', 'конечно', 'конечно', 'корп.', 'который', 'кроме', 'кругом', 'кстати', 'кто', 'кто-кто', 'кто-либо', 'кто-нибудь', 'кто-то', 'ку', 'куда', 'куда-либо', 'куда-нибудь', 'куда-то', 'куды', 'ку-ку', 'кыш', 'ла', 'ладно', 'ле', 'ли', 'либо', 'лишь', 'лучше', 'ль', 'любой', 'м', 'м', 'м.', 'марш', 'мб', 'мбайт', 'мда', 'м-да', 'мдя', 'меж', 'между', 'менее', 'мерси', 'мимо', 'мин.', 'мин.', 'мин-во', 'миним.', 'минус', 'млн', 'мля', 'мм', 'мм', 'м-м', 'ммм', 'м-м-м', 'многие', 'многий', 'много', 'многое', 'может', 'можно', 'мой', 'мол', 'моск.', 'муж.', 'мы', 'мяу', 'на', 'наверное', 'навроде', 'навсегда', 'над', 'надо', 'надо', 'назад', 'наиболее', 'на-ка', 'накануне', 'наконец', 'наперекор', 'наподобие', 'например', 'напротив', 'насчет', 'нате', 'наш', 'н-да', 'не', 'неа', 'не-а', 'небось', 'невесть', 'нед.', 'не-е', 'не-е-ет', 'не-ет', 'нежели', 'неизвестно', 'некий', 'некогда', 'некого', 'некоторые', 'некоторый', 'некто', 'нельзя', 'немногие', 'немногий', 'немногое', 'нет', 'нет', 'нет-нет', 'нет-нет-нет', 'неужели', 'неужто', 'нехай', 'нечего', 'нечто', 'нешто', 'ни', 'нибудь', 'нигде', 'ниже', 'никак', 'никакой', 'никогда', 'никой', 'никто', 'никуда', 'ниоткуда', 'нипочем', 'нисколечко', 'нисколько', 'ниче', 'ничего', 'ничей', 'ничо', 'ничто', 'ничуть', 'ништяк', 'н-не', 'н-нет', 'н-ну', 'но', 'но-но', 'ну', 'нужно', 'ну-ка', 'ну-ко', 'ну-ну', 'ну-с', 'ну-у', 'ну-у', 'нэ', 'о', 'о.', 'об', 'обо', 'оглы', 'ого', 'ого-го', 'о-го-го', 'один', 'однажды', 'однако', 'одно', 'ой', 'ой-ой-ой', 'ок', \"о'кей\", 'около', 'окрест', 'окромя', \"о'кэй\", 'он', 'она', 'они', 'оно', 'оный', 'о-о', 'о-о-о', 'оп', 'опять', 'особенно', 'остальное', 'остальной', 'остальные', 'от', 'откуда', 'откуда-нибудь', 'откуда-то', 'относительно', 'ото', 'отовсюду', 'отсюда', 'отсюдова', 'оттого', 'оттого-то', 'оттуда', 'оттудова', 'отчего', 'отчего-то', 'офф', 'ох', 'ох-хо-хо', 'очень', 'п.', 'п/я', 'пам', 'пардон', 'пер.', 'перед', 'передо', 'пи', 'пиф-паф', 'пли', 'плюс', 'по', 'по-вашему', 'поверх', 'повсюду', 'по-всякому', 'под', 'поди', 'подле', 'подо', 'подобно', 'по-другому', 'поелику', 'пожалуйста', 'по-за', 'позади', 'по-иному', 'пока', 'покамест', 'покуда', 'полноте', 'полундра', 'помимо', 'по-моему', 'по-над', 'по-нашему', 'понеже', 'поперек', 'пос.', 'по-своему', 'посему', 'посередине', 'посередь', 'поскольку', 'после', 'посреди', 'посредине', 'посредством', 'постольку', 'по-твоему', 'потом', 'потому', 'потому-то', 'почем', 'почему', 'почему-либо', 'почему-то', 'почти', 'почто', 'пошто', 'поэтому', 'поэтому-то', 'пп.', 'пр.', 'правда', 'превыше', 'пред', 'предо', 'прежде', 'при', 'притом', 'причем', 'про', 'промеж', 'просп.', 'просто', 'против', 'противу', 'прочая', 'прочее', 'прочий', 'пр-т', 'прям', 'прямо', 'пу', 'пускай', 'пусть', 'путем', 'пущай', 'пшел', 'р.', 'равно', 'равняйсь', 'ради', 'раз', 'разве', 'р-н', 'ровно', 'р-раз', 'руб.', 'рядом', 'с', 'с.', 'сам', 'самый', 'самый-самый', 'сверх', 'свое', 'свой', 'свыше', 'се', 'себе', 'себя', 'сей', 'сейчас', 'сек.', 'сем', 'середь', 'сзади', 'сие', 'сиречь', 'сичас', 'сквозь', 'сколь', 'сколько', 'сколько-нибудь', 'сколько-то', 'сколь-нибудь', 'слишком', 'словно', 'см', 'см.', 'сначала', 'снова', 'со', 'собственно', 'совершенно', 'совсем', 'согласно', 'сообразно', 'соответственно', 'сорри', 'спасибо', 'спасибочки', 'СПб', 'СПб.', 'спустя', 'сразу', 'среди', 'средь', 'сродни', 'столь', 'столько', 'столько-то', 'стоп', 'стр.', 'стук', 'супер', 'супротив', 'сю', 'сюда', 'сюды', 'сяк', 'сякой', 'сям', 'т.', 'т/к', 'та', 'та-ак', 'так', 'также', 'таки', 'тако', 'таков', 'таковой', 'таковский', 'такой', 'такой-сякой', 'такой-то', 'так-так', 'так-таки', 'так-так-так', 'так-то', 'там', 'тама', 'там-то', 'та-та', 'та-та-та', 'твой', 'те', 'тел.', 'тем', 'теперь', 'тик-так', 'типа', 'то', 'тов.', 'тогда', 'тогда-то', 'тож', 'тоже', 'той', 'тока', 'токмо', 'токо', 'только', 'только-то', 'топ', 'то-се', 'тот', 'то-то', 'тот-то', 'точно', 'тра-та-та', 'трах', 'трис', 'тсс', 'тс-с', 'тт.', 'ттт', 'туда', 'туда-сюда', 'туда-то', 'туды', 'тук', 'тук-тук', 'тук-тук-тук', 'тут', 'тута', 'тут-то', 'ту-ту', 'ты', 'тыс.', 'тьфу', 'тьфу-тьфу', 'тьфу-тьфу-тьфу', 'тю', 'у', 'уа', 'увы', 'угодно', 'угу', 'уж', 'уже', 'ужели', 'ужель', 'уй', 'ул.', 'ура', 'усе', 'у-у', 'ууу', 'у-у-у', 'уф', 'ух', 'ф.и.о.', 'фи', 'фио', 'фон', 'фра', 'фу', 'ха', 'ха-ха', 'ха-ха-ха', 'хвать', 'хе', 'хех', 'хе-хе', 'хе-хе-хе', 'хи', 'хи-хи', 'хи-хи-хи', 'хлоп', 'хм', 'хны', 'хо', 'хорошо', 'хоть', 'хотя', 'хо-хо', 'хо-хо-хо', 'хошь', 'хр', 'хрясь', 'хто', 'цоб', 'цыц', 'ч.', 'чаво', 'чай', 'чао', 'че', 'чево', 'чего', 'чегой-то', 'чего-то', 'чей', 'чей-либо', 'чей-нибудь', 'чей-то', 'чем', 'через', 'черт-т', 'че-то', 'чи', 'чик-чик', 'чмок', 'чо', 'чого', 'чрез', 'что', 'чтоб', 'чтобы', 'чтой-то', 'что-либо', 'что-нибудь', 'что-нить', 'что-о', 'что-о-о', 'что-то', 'что-то', 'что-что', 'чу', 'чур', 'чуть', 'чуть', 'ч-черт', 'ша', 'шалом', 'шо', 'шоб', 'што', 'штоб', 'шу', 'ща', 'щелк', 'э', 'эвон', 'эге', 'эдак', 'эдакий', 'эй', 'эк', 'эка', 'экз.', 'экий', 'эль', 'энный', 'эт', 'этак', 'этакий', 'это', 'этот', 'эт-то', 'эх', 'ээ', 'э-э', 'э-эх', 'эээ', 'э-э-э', 'я', 'яко', 'якобы', \"'\", '-', '!', '\"', '#', '$', '%', '&', '(', ')', '*', ',', '.', '/', ':', ';', '?', '@', '[', '\\\\', ']', '^', '_', '{', '|', '}', '~', '+', '=', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'A', 'b', 'B', 'c', 'C', 'd', 'D', 'e', 'E', 'f', 'F', 'g', 'G', 'h', 'H', 'i', 'I', 'j', 'J', 'k', 'K', 'l', 'L', 'm', 'M', 'n', 'N', '№', 'o', 'O', 'p', 'P', 'q', 'Q', 'r', 'R', 's', 'S', 't', 'T', 'u', 'U', 'v', 'V', 'w', 'W', 'x', 'X', 'y', 'Y', 'z', 'Z']\n"
     ]
    }
   ],
   "source": [
    "with open('swl_optimum.txt', 'r', encoding='utf-8') as f:\n",
    "    stop_words_2 = f.readlines()\n",
    "# you may also want to remove whitespace characters like '\\n' at the end of each line\n",
    "stop_words_2 = [x.strip() for x in stop_words_2] \n",
    "\n",
    "print(stop_words_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f235cf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['а', 'е', 'и', 'ж', 'м', 'о', 'на', 'не', 'ни', 'об', 'но', 'он', 'мне', 'мои', 'мож', 'она', 'они', 'оно', 'мной', 'много', 'многочисленное', 'многочисленная', 'многочисленные', 'многочисленный', 'мною', 'мой', 'мог', 'могут', 'можно', 'может', 'можхо', 'мор', 'моя', 'моё', 'мочь', 'над', 'нее', 'оба', 'нам', 'нем', 'нами', 'ними', 'мимо', 'немного', 'одной', 'одного', 'менее', 'однажды', 'однако', 'меня', 'нему', 'меньше', 'ней', 'наверху', 'него', 'ниже', 'мало', 'надо', 'один', 'одиннадцать', 'одиннадцатый', 'назад', 'наиболее', 'недавно', 'миллионов', 'недалеко', 'между', 'низко', 'меля', 'нельзя', 'нибудь', 'непрерывно', 'наконец', 'никогда', 'никуда', 'нас', 'наш', 'нет', 'нею', 'неё', 'них', 'мира', 'наша', 'наше', 'наши', 'ничего', 'начала', 'нередко', 'несколько', 'обычно', 'опять', 'около', 'мы', 'ну', 'нх', 'от', 'отовсюду', 'особенно', 'нужно', 'очень', 'отсюда', 'в', 'во', 'вон', 'вниз', 'внизу', 'вокруг', 'вот', 'восемнадцать', 'восемнадцатый', 'восемь', 'восьмой', 'вверх', 'вам', 'вами', 'важное', 'важная', 'важные', 'важный', 'вдали', 'везде', 'ведь', 'вас', 'ваш', 'ваша', 'ваше', 'ваши', 'впрочем', 'весь', 'вдруг', 'вы', 'все', 'второй', 'всем', 'всеми', 'времени', 'время', 'всему', 'всего', 'всегда', 'всех', 'всею', 'всю', 'вся', 'всё', 'всюду', 'г', 'год', 'говорил', 'говорит', 'года', 'году', 'где', 'да', 'ее', 'за', 'из', 'ли', 'же', 'им', 'до', 'по', 'ими', 'под', 'иногда', 'довольно', 'именно', 'долго', 'позже', 'более', 'должно', 'пожалуйста', 'значит', 'иметь', 'больше', 'пока', 'ему', 'имя', 'пор', 'пора', 'потом', 'потому', 'после', 'почему', 'почти', 'посреди', 'ей', 'два', 'две', 'двенадцать', 'двенадцатый', 'двадцать', 'двадцатый', 'двух', 'его', 'дел', 'или', 'без', 'день', 'занят', 'занята', 'занято', 'заняты', 'действительно', 'давно', 'девятнадцать', 'девятнадцатый', 'девять', 'девятый', 'даже', 'алло', 'жизнь', 'далеко', 'близко', 'здесь', 'дальше', 'для', 'лет', 'зато', 'даром', 'первый', 'перед', 'затем', 'зачем', 'лишь', 'десять', 'десятый', 'ею', 'её', 'их', 'бы', 'еще', 'при', 'был', 'про', 'процентов', 'против', 'просто', 'бывает', 'бывь', 'если', 'люди', 'была', 'были', 'было', 'будем', 'будет', 'будете', 'будешь', 'прекрасно', 'буду', 'будь', 'будто', 'будут', 'ещё', 'пятнадцать', 'пятнадцатый', 'друго', 'другое', 'другой', 'другие', 'другая', 'других', 'есть', 'пять', 'быть', 'лучше', 'пятый', 'к', 'ком', 'конечно', 'кому', 'кого', 'когда', 'которой', 'которого', 'которая', 'которые', 'который', 'которых', 'кем', 'каждое', 'каждая', 'каждые', 'каждый', 'кажется', 'как', 'какой', 'какая', 'кто', 'кроме', 'куда', 'кругом', 'с', 'т', 'у', 'я', 'та', 'те', 'уж', 'со', 'то', 'том', 'снова', 'тому', 'совсем', 'того', 'тогда', 'тоже', 'собой', 'тобой', 'собою', 'тобою', 'сначала', 'только', 'уметь', 'тот', 'тою', 'хорошо', 'хотеть', 'хочешь', 'хоть', 'хотя', 'свое', 'свои', 'твой', 'своей', 'своего', 'своих', 'свою', 'твоя', 'твоё', 'раз', 'уже', 'сам', 'там', 'тем', 'чем', 'сама', 'сами', 'теми', 'само', 'рано', 'самом', 'самому', 'самой', 'самого', 'семнадцать', 'семнадцатый', 'самим', 'самими', 'самих', 'саму', 'семь', 'чему', 'раньше', 'сейчас', 'чего', 'сегодня', 'себе', 'тебе', 'сеаой', 'человек', 'разве', 'теперь', 'себя', 'тебя', 'седьмой', 'спасибо', 'слишком', 'так', 'такое', 'такой', 'такие', 'также', 'такая', 'сих', 'тех', 'чаще', 'четвертый', 'через', 'часто', 'шестой', 'шестнадцать', 'шестнадцатый', 'шесть', 'четыре', 'четырнадцать', 'четырнадцатый', 'сколько', 'сказал', 'сказала', 'сказать', 'ту', 'ты', 'три', 'эта', 'эти', 'что', 'это', 'чтоб', 'этом', 'этому', 'этой', 'этого', 'чтобы', 'этот', 'стал', 'туда', 'этим', 'этими', 'рядом', 'тринадцать', 'тринадцатый', 'этих', 'третий', 'тут', 'эту', 'суть', 'чуть', 'тысяч']\n"
     ]
    }
   ],
   "source": [
    "with open('stop_words_russian.txt', 'r', encoding='utf-8') as f:\n",
    "    stop_words_3 = f.readlines()\n",
    "# you may also want to remove whitespace characters like '\\n' at the end of each line\n",
    "stop_words_3 = [x.strip() for x in stop_words_3] \n",
    "\n",
    "print(stop_words_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1cd868d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим к списку стоп-слов NLTK список слов из stop_words_1\n",
    "stop_words.extend(stop_words_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "5addac92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "d41bad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# используем set(), чтобы удалить дубликаты из списка\n",
    "new_stop_words = list(set(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "cc3b9297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "88e386c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между', 'алло', 'буду', 'будут', 'будь', 'вами', 'ваш', 'ваша', 'ваше', 'ваши', 'весь', 'вон', 'вообще', 'всем', 'всему', 'всею', 'вся', 'всё', 'другие', 'еще', 'ею', 'её', 'затем', 'зато', 'ими', 'каждая', 'каждое', 'каждые', 'кем', 'кого', 'ком', 'кому', 'которая', 'которого', 'которой', 'которые', 'который', 'которых', 'кроме', 'мною', 'мог', 'мои', 'мой', 'мочь', 'моё', 'нам', 'нами', 'наш', 'наша', 'наше', 'наши', 'нем', 'нему', 'нередко', 'нею', 'неё', 'никто', 'ними', 'оба', 'однако', 'одной', 'оно', 'особенно', 'откуда', 'очень', 'сама', 'сами', 'самим', 'самими', 'самих', 'само', 'самой', 'самому', 'саму', 'свое', 'своего', 'своей', 'свои', 'своих', 'свой', 'сих', 'слишком', 'собой', 'сразу', 'та', 'такая', 'также', 'таки', 'такие', 'такое', 'твои', 'твой', 'твоя', 'твоё', 'те', 'тебе', 'теми', 'тех', 'тобой', 'тобою', 'тому', 'ту', 'хотя', 'чаще', 'чему', 'эта', 'этао', 'этим', 'этими', 'этих', 'это', 'этому']\n"
     ]
    }
   ],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d406fc0f",
   "metadata": {},
   "source": [
    "Теперь мы можем просто отфильтровать стоп-слова из нашего списка слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "10c1e4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Для',\n",
       " 'писателя',\n",
       " 'самое',\n",
       " 'ценное',\n",
       " '—',\n",
       " 'читать',\n",
       " ',',\n",
       " 'попадется',\n",
       " 'руки',\n",
       " ',',\n",
       " 'следовать',\n",
       " 'порыву',\n",
       " '.']"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newtokens = [word for word in tokens if word not in stop_words]\n",
    "newtokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486ebf5a",
   "metadata": {},
   "source": [
    "Мы можем дополнительно модифицировать наш вектор, используя лемматизацию и выделение корней, которые представляют собой методы, используемые для приведения слов к их корневой форме.\n",
    "\n",
    "В следующем фрагменте кода показан пример выполнения лемматизации с использованием WordNetlemmatizerмодуля библиотеки NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "c1ad383e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Kasutaja\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet') # need to download first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "92e09c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Never', 'make', 'fun', 'of', 'someone', 'who', 'speaks', 'broken', 'English', '.', 'It', 'mean', 'they', 'know', 'another', 'language']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "text = 'Never make fun of someone who speaks broken English. It means they know another language'\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokens=[lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "81d35681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['иде', 'о', 'том', ',', 'что', 'мышлен', 'и', 'язык', '—', 'одн', 'и', 'то', 'же', ',', '—', 'эт', 'пример', 'тог', ',', 'что', 'может', 'быт', 'назва', 'общепринят', 'заблужден', ':', 'нек', 'утвержден', 'противореч', 'сам', 'очевидн', ',', 'но', 'тем', 'не', 'мен', ',', 'все', 'в', 'нег', 'вер', ',', 'поскольк', 'кажд', 'смутн', 'помн', ',', 'что', 'он', 'эт', 'где-т', 'слыша', 'ил', 'пот', 'что', 'эт', 'утвержден', 'можн', 'истолкова', 'неоднозначн', '.', '(', 'к', 'так', 'заблужден', 'относ', ',', 'например', ',', 'тот', '«', 'факт', '»', ',', 'что', 'мы', 'использу', 'тольк', 'пят', 'процент', 'наш', 'мозг', ';', 'что', 'лемминг', 'соверша', 'массов', 'самоубийств', ';', 'что', '«', 'руководств', 'для', 'бойскаут', '»', '—', 'сам', 'ежегодн', 'продава', 'книг', ';', 'что', 'можн', 'управля', 'продаж', ',', 'воздейству', 'на', 'подсознан', 'покупател', '.', ')', 'подума', 'вот', 'о', 'чем', '.', 'всем', 'нам', 'случа', 'произнест', 'ил', 'написа', 'нек', 'предложен', ',', 'а', 'пот', 'останов', ',', 'сообраз', ',', 'что', 'эт', 'отнюд', 'не', 'то', ',', 'что', 'мы', 'хотел', 'сказа', '.', 'для', 'появлен', 'так', 'чувств', 'необходим', ',', 'чтоб', 'был', 'то', ',', '«', 'что', 'мы', 'хотел', 'сказа', '»', ',', 'отличн', 'от', 'тог', ',', 'что', 'мы', 'сказа', '.', 'пор', 'далек', 'не', 'прост', 'найт', 'люб', 'слов', ',', 'в', 'полн', 'мер', 'выража', 'мысл', '.', 'когд', 'мы', 'слыш', 'ил', 'чита', ',', 'мы', 'обычн', 'запомина', 'смысл', ',', 'а', 'не', 'сам', 'слов', ',', 'так', 'что', 'должн', 'существова', 'так', 'вещ', ',', 'как', 'смысл', ',', 'котор', 'не', 'ест', 'то', 'же', 'сам', ',', 'что', 'и', 'набор', 'слов', '.', 'и', 'есл', 'бы', 'мысл', 'зависел', 'от', 'слов', ',', 'как', 'вообщ', 'можн', 'был', 'бы', 'создава', 'нов', 'слов', '?', 'как', 'мог', 'бы', 'ребенок', 'выуч', 'сво', 'сам', 'перв', 'слов', '?', 'как', 'бы', 'существова', 'возможн', 'перевод', 'с', 'одн', 'язык', 'на', 'друг', '?']\n"
     ]
    }
   ],
   "source": [
    "# для русского языка\n",
    "from nltk.stem.snowball import SnowballStemmer \n",
    "\n",
    "text = 'Идея о том, что мышление и язык — одно и то же, — это пример того, что может \\\n",
    "быть названо общепринятым заблуждением: некое утверждение противоречит самому очевидному, \\\n",
    "но тем не менее, все в него верят, поскольку каждый смутно помнит, что он это где-то слышал \\\n",
    "или потому что это утверждение можно истолковать неоднозначно. (К таким заблуждениям относится, \\\n",
    "например, тот «факт», что мы используем только пять процентов нашего мозга; что лемминги совершают \\\n",
    "массовые самоубийства; что «Руководство для бойскаута» — самая ежегодно продаваемая книга; \\\n",
    "что можно управлять продажами, воздействуя на подсознание покупателя.) Подумайте вот о чем. \\\n",
    "Всем нам случалось произнести или написать некое предложение, а потом остановиться, сообразив, \\\n",
    "что это отнюдь не то, что мы хотели сказать. Для появления такого чувства необходимо, чтобы было то, \\\n",
    "«что мы хотели сказать», отличное от того, что мы сказали. Порой далеко не просто найти любые слова, \\\n",
    "в полной мере выражающие мысль. Когда мы слышим или читаем, мы обычно запоминаем смысл, а не сами слова, \\\n",
    "так что должна существовать такая вещь, как смысл, который не есть то же самое, что и набор слов. \\\n",
    "И если бы мысли зависели от слов, как вообще можно было бы создавать новые слова? Как мог бы ребенок \\\n",
    "выучить свое самое первое слово? Как бы существовала возможность перевода с одного языка на другой?'\n",
    "\n",
    "\n",
    "stemmer.stem(text)\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "stemmer = SnowballStemmer(\"russian\") \n",
    "tokens=[stemmer.stem(word) for word in tokens]\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "cf3422b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['never', 'make', 'fun', 'of', 'someon', 'who', 'speak', 'broken', 'english', '.', 'it', 'mean', 'they', 'know', 'anoth', 'languag']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = 'Never make fun of someone who speaks broken English. It means they know another language'\n",
    "\n",
    "tokens=word_tokenize(text.lower())\n",
    "ps = PorterStemmer()\n",
    "tokens=[ps.stem(word) for word in tokens]\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118ffccf",
   "metadata": {},
   "source": [
    "#### Тегирование части речи\n",
    "Тегирование части речи (тегирование POS) определяет часть речи (существительное, глагол, наречие и т. д.) каждого слова в предложении. Это важный шаг для многих приложений NLP, поскольку, определяя POS слова, мы можем вывести его контекстуальное значение. Например, значение слова «сталь» отличается, когда оно используется как существительное; например, \"этот ящик из стали\" по сравнению с тем, когда оно используется в качестве глагола, например, \"дети стали намного спокойнее\".\n",
    "\n",
    "Обратитесь к следующему фрагменту кода, чтобы выполнить маркировку POS с помощью NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "ff23a664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Kasutaja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger') # need to download first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "d9500321",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fatally', 'RB')]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag([\"fatally\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "41c65f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fate', 'NN')]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag([\"fate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "2408a3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('diabolical', 'JJ')]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag([\"diabolical\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d043496c",
   "metadata": {},
   "source": [
    "Доступ к исчерпывающему списку POS-тегов NLTK можно получить с помощью upenn_tagset() функции NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "0b307e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\Kasutaja\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$: dollar\n",
      "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
      "'': closing quotation mark\n",
      "    ' ''\n",
      "(: opening parenthesis\n",
      "    ( [ {\n",
      "): closing parenthesis\n",
      "    ) ] }\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "EX: existential there\n",
      "    there\n",
      "FW: foreign word\n",
      "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
      "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
      "    terram fiche oui corporis ...\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "LS: list item marker\n",
      "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
      "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
      "    two\n",
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "PDT: pre-determiner\n",
      "    all both half many quite such sure this\n",
      "POS: genitive marker\n",
      "    ' 's\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "RBR: adverb, comparative\n",
      "    further gloomier grander graver greater grimmer harder harsher\n",
      "    healthier heavier higher however larger later leaner lengthier less-\n",
      "    perfectly lesser lonelier longer louder lower more ...\n",
      "RBS: adverb, superlative\n",
      "    best biggest bluntest earliest farthest first furthest hardest\n",
      "    heartiest highest largest least less most nearest second tightest worst\n",
      "RP: particle\n",
      "    aboard about across along apart around aside at away back before behind\n",
      "    by crop down ever fast for forth from go high i.e. in into just later\n",
      "    low more off on open out over per pie raising start teeth that through\n",
      "    under unto up up-pp upon whole with you\n",
      "SYM: symbol\n",
      "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "UH: interjection\n",
      "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
      "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
      "    man baby diddle hush sonuvabitch ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n",
      "WP: WH-pronoun\n",
      "    that what whatever whatsoever which who whom whosoever\n",
      "WP$: WH-pronoun, possessive\n",
      "    whose\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "``: opening quotation mark\n",
      "    ` ``\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping help\\tagsets.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('tagsets') # need to download first time\n",
    "nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b38d9bc",
   "metadata": {},
   "source": [
    "POS в библиотеке NLTK выводит определенные теги для определенных слов. Ниже приведен список тегов POS с примерами того, что означает каждый POS.  \n",
    "\n",
    "The POS tagger in the NLTK library outputs specific tags for certain words. The list of POS tags is as follows, with examples of what each POS stands for.\n",
    "\n",
    "CC coordinating conjunction  \n",
    "CD cardinal digit  \n",
    "DT determiner  \n",
    "EX existential there (like: “there is” … think of it like “there exists”)  \n",
    "FW foreign word  \n",
    "IN preposition/subordinating conjunction  \n",
    "JJ adjective ‘big’  \n",
    "JJR adjective, comparative ‘bigger’  \n",
    "JJS adjective, superlative ‘biggest’  \n",
    "LS list marker 1)  \n",
    "MD modal could, will  \n",
    "NN noun, singular ‘desk’  \n",
    "NNS noun plural ‘desks’  \n",
    "NNP proper noun, singular ‘Harrison’  \n",
    "NNPS proper noun, plural ‘Americans’  \n",
    "PDT predeterminer ‘all the kids’  \n",
    "POS possessive ending parent’s  \n",
    "PRP personal pronoun I, he, she  \n",
    "PRP$ possessive pronoun my, his, hers  \n",
    "RB adverb very, silently,  \n",
    "RBR adverb, comparative better  \n",
    "RBS adverb, superlative best  \n",
    "RP particle give up  \n",
    "TO, to go ‘to’ the store.  \n",
    "UH interjection, errrrrrrrm  \n",
    "VB verb, base form take  \n",
    "VBD verb, past tense took  \n",
    "VBG verb, gerund/present participle taking  \n",
    "VBN verb, past participle taken  \n",
    "VBP verb, sing. present, non-3d take  \n",
    "VBZ verb, 3rd person sing. present takes  \n",
    "WDT wh-determiner which  \n",
    "WP wh-pronoun who, what   \n",
    "WP possessive wh-pronoun whose  \n",
    "WRB wh-abverb where, when  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c691e417",
   "metadata": {},
   "source": [
    "Мы можем сгенерировать POS для каждого слова предложения, перебирая список токенов и применяя pos_tag() функцию по отдельности.   Следующий код является примером того, как теги POS могут выполняться итеративно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "6823519d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Never', 'RB')],\n",
       " [('make', 'VB')],\n",
       " [('fun', 'NN')],\n",
       " [('of', 'IN')],\n",
       " [('someone', 'NN')],\n",
       " [('who', 'WP')],\n",
       " [('speaks', 'NNS')],\n",
       " [('broken', 'NN')],\n",
       " [('English', 'JJ')],\n",
       " [('.', '.')],\n",
       " [('It', 'PRP')],\n",
       " [('means', 'NNS')],\n",
       " [('they', 'PRP')],\n",
       " [('know', 'VB')],\n",
       " [('another', 'DT')],\n",
       " [('language', 'NN')]]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "[nltk.pos_tag([word]) for word in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f905c21e",
   "metadata": {},
   "source": [
    "#### Textblob\n",
    "\n",
    "Textblob — это популярная библиотека, используемая для анализа тональности, тегирования частей речи, перевода и т. д. Она построена поверх других библиотек, включая NLTK, и имеет очень простой в использовании интерфейс, что делает его незаменимым для новичков в NLP. \n",
    "\n",
    "Вы можете обратиться к документации Textblob, https://textblob.readthedocs.io/en/dev/ , или посетить его страницу GitHub, https://github.com/sloria/TextBlob, чтобы подробно познакомиться с этой библиотекой."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78472c1",
   "metadata": {},
   "source": [
    "####  Анализ настроений\n",
    "Анализ тональности — важная область исследований в NLP, целью которой является анализ текста и оценка его тональности. Библиотека Textblob позволяет пользователям анализировать тональность данного фрагмента текста очень удобным способом. Документация по библиотеке Textblob (https://textblob.readthedocs.io/en/dev/) довольно подробная, легко читаемая, а также содержит учебные пособия.\n",
    "\n",
    "Мы можем установить textblob библиотеку и загрузить связанные корпуса, выполнив следующие команды в командной строке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeee20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U textblob\n",
    "python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86fc60c",
   "metadata": {},
   "source": [
    "Обратитесь к следующему фрагменту кода, чтобы увидеть, насколько удобно использовать библиотеку для расчета тональности:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "9a8406cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.5, subjectivity=0.6)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "TextBlob(\"I love pizza\").sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd52e5d5",
   "metadata": {},
   "source": [
    "После импорта библиотеки TextBlob всё, что нам нужно сделать для расчета тональности, — это передать текст, который необходимо проанализировать, и использовать модуль тональности библиотеки.  \n",
    "Модуль настроений выводит кортеж с оценкой полярности и оценкой субъективности. Оценка полярности варьируется от -1 до 1, где -1 наиболее негативные настроения и 1 наиболее позитивные утверждения. Оценка субъективности колеблется от 0 до 1, при этом оценка 0 подразумевает, что утверждение соответствует действительности, тогда как оценка 1 подразумевает в высшей степени субъективное утверждение.\n",
    "\n",
    "Для предыдущего утверждения, I love pizza, мы получаем показатель полярности 0.5, подразумевая положительное настроение. Субъективность предыдущего утверждения также оценивается как высокая, что кажется правильным."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1041f69b",
   "metadata": {},
   "source": [
    "TextBlob поддерживает только английский язык. Для русского языка есть библиотека dostoevsky (https://github.com/bureaucratic-labs/dostoevsky)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e6144f",
   "metadata": {},
   "source": [
    "#### Машинный перевод\n",
    "Textblob использует API Google Translator для предоставления очень простого интерфейса перевода текста. Просто используйте функцию translate() для перевода заданного текста на нужный язык (из каталога языков Google).\n",
    "\n",
    "Список языковых кодов можно получить на странице https://cloud.google.com/translate/docs/basic/translating-text#language-params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56b3ea49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning!\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "blob = TextBlob(\"Buongiorno!\")\n",
    "print(blob.translate(from_lang ='it', to='en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3adf41c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'en'\n",
    "languages = ['ru', 'fr', 'it']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec35ad21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "случайность\n",
      "sérendipité\n",
      "colpo di fortuna\n"
     ]
    }
   ],
   "source": [
    "blob = TextBlob(\"serendipity\")\n",
    "\n",
    "for language in languages:\n",
    "    print(blob.translate(from_lang = lang, to=language))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465ea910",
   "metadata": {},
   "source": [
    "Это всего лишь несколько популярных приложений Textblob, демонстрирующих простоту использования и универсальность программы. Существует множество других приложений Textblob, и вам предлагается изучить их. Хорошим местом для начала знакомства с Textblob и ознакомления с другими приложениями Textblob будет учебник по Textblob, доступ к которому можно получить по адресу https://textblob.readthedocs.io/en/dev/quickstart.html."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
